{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   47.1s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PLAN (BabI task 1)\n",
    "\n",
    "given input:\n",
    "- fact 1   | John travelled to the hallway.\n",
    "- fact 2   | Mary journeyed to the bathroom.\n",
    "- question | Where is John?\n",
    "\n",
    "output:\n",
    "- answer   | hallway\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "#    ('clf', ExtraTreesClassifier()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10, 50, 100],\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [1, 2, 3, 5, 8, 13],\n",
    "    'clf__max_features': [1, 2, 3, 5, 8, 13],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "from parse_dataset import parse_data\n",
    "\n",
    "df_train = parse_data('/Users/enrico.t/code/ml-reference-implementations/' + \n",
    "                      'data/babI/tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt')\n",
    "\n",
    "X_train = df_train['fact1'] + ' ' + df_train['fact2'] + ' ' + df_train['question']\n",
    "y_train = df_train['answer']\n",
    "\n",
    "df_test = parse_data('/Users/enrico.t/code/ml-reference-implementations/' + \n",
    "                     'data/babI/tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "X_test = df_test['fact1'] + ' ' + df_test['fact2'] + ' ' + df_test['question']\n",
    "y_test = df_test['answer']\n",
    "\n",
    "model = GridSearchCV(\n",
    "    pipeline, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(y_test, y_predict)\n",
    "cm.print_stats()\n",
    "print cm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-reference-implementations",
   "language": "python",
   "name": "ml-reference-implementations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
